# MedGemma

MedGemma系列包含Google在医学文本和图像理解方面最强大的开源模型，基于Gemma 3构建。开发人员可以使用MedGemma加速构建基于医疗保健的AI应用程序。MedGemma有两个版本：4B多模态版本和27B纯文本版本。

有关如何使用模型以及训练方式的详细信息，请参阅MedGemma模型卡片。

## 常见用例
以下部分介绍了该模型的一些常见用例。您可以自由探索任何用例，只要遵守Health AI Developer Foundations使用条款。

### 医学图像分类
MedGemma 4B的预训练使其成为适用于医学图像分类的良好起点，包括放射学、数字病理学、眼底和皮肤图像。MedGemma与同等规模的类似模型相比，基线性能表现强劲，但开发人员应在生产环境中部署之前验证其性能并进行必要的改进。

### 医学图像解读
MedGemma 4B的预训练使其成为生成医学图像报告或回答关于医学图像的自然语言问题的良好起点。MedGemma与同等规模的类似模型相比基线性能强劲，但尚未达到临床级别，因此可能需要额外的微调。

### 医学文本理解和临床推理
MedGemma可以适用于需要医学知识的用例。此类用例可能包括患者访谈、分诊、临床决策支持和摘要。对于大多数用例，较大的MedGemma 27B模型通常会产生最佳性能。两种规模的MedGemma与同等规模的类似模型相比都具有强劲的基线性能，但开发人员应在生产环境中部署之前验证其适配模型的性能并进行必要的改进。

## 适配MedGemma
MedGemma是一个开发者模型，需要在开发者的预期用例上进行验证。基于这些验证结果，用户可能需要进一步适配模型以提高性能。以下是开发人员可以用来提高MedGemma在其用例中性能的一些适配类型。

### 提示工程/上下文学习
对于某些用例，通过仔细的提示，MedGemma的基线性能可能就足够了，这可能包括在提示中包含理想示例响应的少样本示例，换句话说就是上下文学习。提示工程也可以使用MedGemma将任务分解为可以单独执行的子任务。使用提示工程的适配需要与任何其他类型的适配相同级别的验证。

### 微调
可以对MedGemma进行微调，以提高其在已训练任务上的性能，或为其添加额外的任务。有关如何使用LoRA（一种参数高效的微调技术）微调MedGemma的示例，请参阅此笔记本。

用户可以专门微调语言模型解码器组件，以帮助模型更好地解释图像编码器产生的视觉令牌，或者同时微调两者。

### 智能体编排
MedGemma可以作为智能体系统中的工具使用，与其他工具结合，如网络搜索、FHIR生成器/解释器、用于双向音频对话的Gemini Live，或用于函数调用或推理的Gemini 2.5 Pro。MedGemma也可以用于在本地解析私人健康数据，然后将匿名化请求发送到像Gemini 2.5 Pro这样的集中式模型。

## 下一步

开始使用模型